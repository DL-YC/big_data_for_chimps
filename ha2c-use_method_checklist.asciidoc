[[use_method]]
=== The USE Method applied to Hadoop ===

There's an excellent methodology for performance analysis known as the http://dtrace.org/blogs/brendan/2012/02/29/the-use-method/["USE Method"]: "For every resource, check Utilization, Saturation and Errors" footnote:[developed by Brendan Gregg for system performance tuning, modified here for Hadoop]:

* utilization -- How close to capacity is the resource? (ex: CPU usage, % disk used)
* saturation  -- How often is work waiting? (ex: network drops or timeouts)
* errors      -- Are there error events?

For example, if our resource were a supermarket checkout cashier, some USE metrics would include:

* utilization: flow of items across the belt; constantly stopping to look up the price of tomatoes or check coupons will harm utilization.
* saturation: number of customers waiting in line
* errors: calling for the manager

As you can see, it's possible to have low utilization and high saturation (a cashier in training with a long line), high utilization and low saturation (steady stream of customers but no line), or any other combination.

===== Resource List =====

The USE method can help you identify the limiting resource of a job, to diagnose a faulty or misconfigured system, and to guide tuning and provisioning of the base system.

* system CPU
* system memory
* system disk IO
* system disk 

Please see the <<glossary>> for definitions of terms.

* mapper task CPU
* mapper taks 
Network interface -- throughput
Storage devices	  -- throughput, capacity
Controllers	  -- storage, network cards
Interconnects	  -- CPUs, memory, throughput

* disk throughput
* handler threads
* garbage collection events

I've borrowed many of the system-level metrics from http://dtrace.org/blogs/brendan/2012/03/07/the-use-method-linux-performance-checklist/[Brendan Gregg's Linux Checklist]; visit there for a more-detailed list.

[[use_method_table]]
.USE Method Checklist
[options="header"]
|=======
| resource              | type        	| metric 		| instrument
|			|		|  			|
| *CPU-like concerns*	|		|  			|
|			|		|  			|
| CPU    		| utilization	| system CPU		| `top`/`htop`: CPU %, overall
|			|		| job process CPU	| `top`/`htop`: CPU %, each child process
| mapper slots		| utilization	| mapper slots used	| jobtracker console; impacted by `mapred.tasktracker.map.tasks.maximum`
| mapper slots  	| saturation	| mapper tasks waiting	| jobtracker console; impacted by scheduler and by speculative execution settings
| reducer slots		| utilization	| reducer slots used	| jobtracker console; impacted by `mapred.tasktracker.reduce.tasks.maximum`
| reducer slots 	| saturation	| reducer tasks waiting	| jobtracker console; impacted by scheduler and by speculative execution and slowstart settings
| task startup overhead	|		|  			|
|			|		|  			|
| *memory concerns*	|		|  			|
|			|		|  			|
| memory capacity	| utilization	| total non-OS RAM	| `free`, `htop`; you want the total excluding caches+buffers.
|			|		| child process RAM	| `free`, `htop`: "RSS"; impacted by `mapred.map.child.java.opts` and `mapred.reduce.child.java.opts`
|			| 		| JVM old-gen used 	| JMX
|			| 		| JVM new-gen used	| JMX
| memory capacity	| saturation	| swap activity		| `vmstat 1` - look for "r" > CPU count.
|			|		| old-gen gc count   	| JMX, gc logs (must be specially enabled)
|			|		| old-gen gc pause time	| JMX, gc logs (must be specially enabled)
|			|		| new-gen gc pause time	| JMX, gc logs (must be specially enabled)
| mapper sort buffer	| utilization	| record size limit	| announced in job process logs; controlled indirectly by `io.sort.record.percent`, spill percent tunables
|			|		| record count limit	| announced in job process logs; controlled indirectly by `io.sort.record.percent`, spill percent tunables
| mapper sort buffer	| saturation	| spill count		| spill counters (jobtracker console)
|			|		| sort streams		| io sort factor tunable (`io.sort.factor`)
| shuffle buffers	| utilization	| buffer size		| child process logs
|			|		| buffer %used		| child process logs
| shuffle buffers	| saturation	| spill count		| spill counters (jobtracker console)
|			|		| sort streams		| merge parallel copies tunable `mapred.reduce.parallel.copies` (TODO: also `io.sort.factor`?)
| OS caches/buffers	| utilization	| total c+b		| `free`, `htop`
|			|		|  			|
| *disk concerns*	|		|  			|
|			|		|  			|
| system disk I/O	| utilization	| req/s, read		| `iostat -xz 1` (system-wide); `iotop` (per process); `/proc/{PID}/sched` "se.statistics.iowait_sum"
|			|		| req/s, write		| `iostat -xz 1` (system-wide); `iotop` (per process); `/proc/{PID}/sched` "se.statistics.iowait_sum"
|			|		| MB/s, read		| `iostat -xz 1` (system-wide); `iotop` (per process); `/proc/{PID}/sched` "se.statistics.iowait_sum"
|			|		| MB/s, write		| `iostat -xz 1` (system-wide); `iotop` (per process); `/proc/{PID}/sched` "se.statistics.iowait_sum"
| system disk I/O	| saturation	| queued requests	| `iostat -xnz 1`; look for "avgqu-sz" > 1, or high "await".
| 			|		| open file handles	| `ulimit -n` ("nofile" in `/etc/security/limits.d/...`)
| 			|		| max user processes	| `ulimit -u` ("noproc" in `/etc/security/limits.d/...`)
| system disk I/O	| errors	|  			| `/sys/devices/â€¦/ioerr_cnt`; `smartctl`, `/var/log/messages`
|			|		|  			|
| *network concerns*	|		|  			|
|			|		|  			|
| network I/O		| utilization	| 			| `netstat`; `ip -s {link}`; `/proc/net/{dev}` -- RX/TX throughput as fraction of max bandwidth
| network I/O		| saturation	| 			| `ifconfig` ("overruns", "dropped"); `netstat -s` ("segments retransmited"); `/proc/net/dev` (RX/TX "drop")
| network I/O		| errors	| interface-level	| `ifconfig` ("errors", "dropped");   `netstat -i` ("RX-ERR"/"TX-ERR"); `/proc/net/dev` ("errs", "drop")
|			| 		| request timeouts	| daemon and child process logs
| handler threads	| utilization	|  			|
|			|		| nn handlers		| (TODO: how to measure) vs `dfs.namenode.handler.count`
|			|		| jt handlers		| (TODO: how to measure) vs 
|			|		| dn handlers		| (TODO: how to measure) vs `dfs.datanode.handler.count`
|			|		| dn xceivers		| (TODO: how to measure) vs `dfs.datanode.max.xcievers
|			|		|  			|
| *framework concerns*	|		|  			|
|			|		|  			|
| disk capacity		| 		| system disk used	| `df -bM`
|			|		| HDFS directories	| `du -smc /path/to/mapred_scratch_dirs` (for all directories in `dfs.data.dir`, `dfs.name.dir`, `fs.checkpoint.dir`)
|			|		| mapred scratch space	| `du -smc /path/to/mapred_scratch_dirs` (TODO scratch dir tunable)
|			|		| total HDFS free	| namenode console
| job process		| errors	| 			| stderr log
|            		|       	| 			| stdout log
|            		|        	| 			| counters
| datanode		| errors	| 			|
| namenode		| errors	| 			|
| secondarynn		| errors	| 			|
| tasktracker		| errors	| 			|
| jobtracker		| errors	| 			|
|=======

Metrics:

* number of spills
* disk {read,write} {req/s,MB/s}
* CPU % {by process}
* GC
  - heap used (total, %)
  - new gen pause
  - old gen pause
  - old gen rate
  - STW count
* system memory
  - resident ram {by process}
  - paging
* network interface
  - throughput {read, write}
  - queue
* handler threads
  - handlers
  - xceivers
* 


Exchanges:

* 
* shuffle buffers -- memory for disk
* gc options -- CPU for memory


If at all possible, use a remote monitoring framework like Ganglia, Zabbix or Nagios. However http://sourceforge.net/projects/clusterssh[clusterssh] or http://code.google.com/p/csshx[its OSX port] along with the following commands will help


===== Exercises =====

For each of the utilization and saturation metrics listed above, describe job or tunable adjustments that would drive it to an extreme. For example, the obvious way to drive shuffle saturation (number of merge passes after mapper completion) is to bring a ton of data down on one reducer -- but excessive map tasks or a `reduce_slowstart_pct` of 100% will do so as well.


