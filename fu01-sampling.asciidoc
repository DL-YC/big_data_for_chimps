== Sampling ==

* Random sample:
  ** fixed size of final sample
  ** fixed probability (binomial) for each element
  ** spatial sampling
  ** with/without replacement
  ** weighted
  ** by interestingness
  ** stratified: partition important features into bins, and sample tastefully to achieve a smooth selection across bins. Think of density of phase space
  ** consistent sample: the same sampling parameters on the same population will always return the same sample.
* Algorithms:
  ** iterative
  ** batch
  ** scan
  ** reservoir

* graph:
  ** sample to preserve connectivity
  ** sample to preserve local structure
  ** sample to preserve global representation


We're not going to worry about extracting samples larger than fit on one reducer.


=== Random Sampling ===

"Binomial" sampling -- emit each line with fraction

To take a random sample, fraction `p` of the full dataset:
* write a mapper that emits lines with probability `p`
* use a null reducer or no reducer ("-D mapred.reduce.tasks=0")

**(don't do this -- random numbers in hadoop jobs == bad)**

A [http://github.com/mrflip/wukong/blob/master/examples/sample_records.rb Ruby example] is available in the wukong examples:

<pre>
#
# Probabilistically emit some fraction of record/lines
#
# Set the sampling fraction at the command line using the
#   --sampling_fraction=
# option: for example, to take a random 1/1000th of the lines in huge_files,
#  ./examples/sample_records.rb --sampling_fraction=0.001 --go huge_files sampled_files
#
class Mapper < Wukong::Streamer::LineStreamer
  include Wukong::Streamer::Filter

  #
  # floating-point number between 0 and 1 giving the fraction of lines to emit:
  # at sampling_fraction=1 all records are emitted, at 0 none are.
  #
  def sampling_fraction
    @sampling_fraction ||= ( options[:sampling_fraction] && options[:sampling_fraction].to_f ) or
      raise "Please supply a --sampling_fraction= argument, a decimal number between 0 and 1"
  end

  # randomly decide to emit +sampling_fraction+ fraction of lines
  def emit? line
    rand < self.sampling_fraction
  end
end

# Execute the script with nil reducer
Script.new( Mapper, nil ).run
</pre>

=== Random Sampling using strides ===

Another, often faster, way of doing random sampling is to
generate a geometrically-distributed (rather than uniformly-distributed) sampling series
For each value `R`, Your mapper skips `R` lines and 

=== Consistent Sampling ===

See this [http://blog.rapleaf.com/dev/?p=187 rapleaf blog post]


=== Constant-Memory "Reservoir" Sampling ===

Want to generate a sample of fixed size N_s -- say, 1000 arbitrary records -- no matter how large or small the dataset. (Clearly if it is smaller than N_s, you will emit the full dataset).

Suppose you assigned every record an arbitrary sample key, and sorted on that key. Choosing the first N_s records would be a fair way to get our sample.
In fact, this is how most card games work: shuffle the records (cards) into an arbitrary order, and draw a fixed-size batch of cards from the collection.

But! of course, a total sort is very expensive. As you may guess, it's unnecessary.

Each mapper creates a "reservoir", of size N_s, for the rows it will select. Add each record to the reservoir, and if there are more than N_s occupants, reject the record with highest sample index. (in practice, you won't even add the record if it would be that highest record).
A Fibonacci heap (implementing a priority queue) makes this very efficient

Ruby's stdlib has a `SortedSet` class -- a Set that guarantees that it's element are yielded in sorted order (according to the return values of their `#<=>` methods) when iterating over them.


Each mapper outputs the sampling index of each preserved row as the key, and the rest of the row as the value; 

It's essential that you keep the sampling index given by the first pass.



=== References ===


* http://db.cs.berkeley.edu/papers/UCB-PhD-olken.pdf[Random Sampling from Databases], Frank Olken, 1993

* containers:
  ** https://github.com/skade/rbtree[RBTree] for ruby
  ** https://github.com/rubyworks/pqueue[Priority Queue]

* http://stackoverflow.com/a/2584770/41857[Stack Overflow: How to pick random (small) data samples using Map/Reduce?, answer by Bkkbrad]
